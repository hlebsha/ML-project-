{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbee551-72a0-4997-a786-07adfc95c7a0",
   "metadata": {},
   "source": [
    "**Loading images and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b5189c-ff08-4fda-9226-1d19f692e5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def load_data(data_dir, augment=False):\n",
    "    images, labels = [], []\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    for label in os.listdir(data_dir):\n",
    "        for image_file in os.listdir(os.path.join(data_dir, label)):\n",
    "            img = image.load_img(os.path.join(data_dir, label, image_file), target_size=(256, 256))\n",
    "            img_tensor = image.img_to_array(img)\n",
    "            img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "            img_tensor /= 255.  # normalize to [0,1] range\n",
    "\n",
    "            if augment:\n",
    "                aug_images = [img_tensor]\n",
    "                for batch in datagen.flow(img_tensor, batch_size=1):\n",
    "                    aug_images.append(batch)\n",
    "                    if len(aug_images) >= 6:  # original + 5 augmented images\n",
    "                        break\n",
    "                img_tensor = np.concatenate(aug_images, axis=0)\n",
    "\n",
    "            images.append(img_tensor)\n",
    "            labels.extend([label] * len(img_tensor))\n",
    "\n",
    "    return np.concatenate(images, axis=0), np.array(labels)\n",
    "\n",
    "images, labels = load_data('ds', augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0f71-9eda-499e-abbf-c2c1089fc28b",
   "metadata": {},
   "source": [
    "**DS split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d13d9bea-207b-4158-b68f-c85047bd0ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3196, 256, 256, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0c336-48f8-452c-92d1-41d318572dc2",
   "metadata": {},
   "source": [
    "**Model teaching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "272c1388-8cf7-4d9d-b6a3-321737ebf3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "#tf.keras.utils.plot_model(model)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0eaac-37df-4756-a0de-6c540d33af5f",
   "metadata": {},
   "source": [
    "**Predict and evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf8ec86-8c22-491d-a402-c751ae3de112",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7813477",
   "metadata": {},
   "source": [
    "Solution for first rough pipeline:\n",
    "\n",
    "Accuracy: 57%\n",
    "\n",
    "Problem: Dataset is very imbalanced because category palm has 374 images, fist has 200 and thumb has 92. So neural network just pivots toward classificating everything as palm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
