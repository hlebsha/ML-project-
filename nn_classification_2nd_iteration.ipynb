{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbee551-72a0-4997-a786-07adfc95c7a0",
   "metadata": {},
   "source": [
    "**Loading images and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b5189c-ff08-4fda-9226-1d19f692e5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(532, 256, 256, 3) (532,)\n",
      "Counter({'Palm': 299, 'Fist': 160, 'Thumb': 73})\n",
      "(134, 256, 256, 3) (134, 256, 256, 3)\n",
      "Counter({'Palm': 75, 'Fist': 40, 'Thumb': 19})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def count_classes(data_dir):\n",
    "    labels = []\n",
    "    for label in os.listdir(data_dir):\n",
    "        for image_file in os.listdir(os.path.join(data_dir, label)):\n",
    "            labels.append(label)\n",
    "    return Counter(labels)\n",
    "\n",
    "def load_data(data_dir):\n",
    "    images, labels = [], []\n",
    "    for label in os.listdir(data_dir):\n",
    "        for image_file in os.listdir(os.path.join(data_dir, label)):\n",
    "            img = image.load_img(os.path.join(data_dir, label, image_file), target_size=(256, 256))\n",
    "            img_tensor = image.img_to_array(img)\n",
    "            img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "            img_tensor /= 255.  # normalize to [0,1] range\n",
    "\n",
    "            images.append(img_tensor)\n",
    "            labels.extend([label] * len(img_tensor))\n",
    "\n",
    "    return np.concatenate(images, axis=0), np.array(labels)\n",
    "\n",
    "def augment_data(images, labels, class_counts):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    augmented_images, augmented_labels = [], []\n",
    "    max_images = max(class_counts.values())\n",
    "    for img_tensor, label in zip(images, labels):\n",
    "        aug_images = [img_tensor]\n",
    "        augmentation_factor = max_images / class_counts[label]\n",
    "        for batch in datagen.flow(np.expand_dims(img_tensor, axis=0), batch_size=1):\n",
    "            aug_images.append(np.squeeze(batch, axis=0))\n",
    "            if len(aug_images) >= math.ceil(20 * augmentation_factor):  # original + augmented images\n",
    "                break\n",
    "        aug_images = np.stack(aug_images, axis=0)  # stack images along a new axis\n",
    "        augmented_images.append(aug_images)\n",
    "        augmented_labels.extend([label] * len(aug_images))\n",
    "\n",
    "    return np.concatenate(augmented_images, axis=0), np.array(augmented_labels)\n",
    "\n",
    "# Load all data without augmentation\n",
    "images, labels = load_data('ds')\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "class_counts = count_classes('ds')\n",
    "# Augment the training data\n",
    "# X_train, y_train = augment_data(X_train, y_train, class_counts)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(Counter(y_train))\n",
    "print(X_test.shape, X_test.shape)\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf0f71-9eda-499e-abbf-c2c1089fc28b",
   "metadata": {},
   "source": [
    "**DS split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13d9bea-207b-4158-b68f-c85047bd0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)\n",
    "y_val = le.transform(y_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f0c336-48f8-452c-92d1-41d318572dc2",
   "metadata": {},
   "source": [
    "**Model teaching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272c1388-8cf7-4d9d-b6a3-321737ebf3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 280ms/step - accuracy: 0.3688 - loss: 14.5867 - val_accuracy: 0.2991 - val_loss: 6.1181\n",
      "Epoch 2/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.4480 - loss: 4.3171 - val_accuracy: 0.6729 - val_loss: 0.9127\n",
      "Epoch 3/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 260ms/step - accuracy: 0.6118 - loss: 1.1855 - val_accuracy: 0.6075 - val_loss: 1.0375\n",
      "Epoch 4/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.6620 - loss: 0.9254 - val_accuracy: 0.7196 - val_loss: 0.6915\n",
      "Epoch 5/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.8157 - loss: 0.4604 - val_accuracy: 0.7196 - val_loss: 0.5549\n",
      "Epoch 6/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.8260 - loss: 0.3890 - val_accuracy: 0.7570 - val_loss: 0.5105\n",
      "Epoch 7/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.8459 - loss: 0.3679 - val_accuracy: 0.8037 - val_loss: 0.6333\n",
      "Epoch 8/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.8291 - loss: 0.4111 - val_accuracy: 0.5327 - val_loss: 1.2929\n",
      "Epoch 9/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.7484 - loss: 0.6340 - val_accuracy: 0.5981 - val_loss: 1.3958\n",
      "Epoch 10/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.8131 - loss: 0.5616 - val_accuracy: 0.8037 - val_loss: 0.5592\n",
      "Epoch 11/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.8864 - loss: 0.2681 - val_accuracy: 0.7103 - val_loss: 0.8365\n",
      "Epoch 12/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.8381 - loss: 0.3408 - val_accuracy: 0.7664 - val_loss: 0.8514\n",
      "Epoch 13/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.8705 - loss: 0.3404 - val_accuracy: 0.6916 - val_loss: 1.3309\n",
      "Epoch 14/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.8029 - loss: 0.6050 - val_accuracy: 0.5047 - val_loss: 2.0890\n",
      "Epoch 15/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.6493 - loss: 1.1365 - val_accuracy: 0.5981 - val_loss: 1.0941\n",
      "Epoch 16/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.7258 - loss: 0.6894 - val_accuracy: 0.8131 - val_loss: 0.5068\n",
      "Epoch 17/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.8602 - loss: 0.3944 - val_accuracy: 0.6449 - val_loss: 0.9607\n",
      "Epoch 18/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.8691 - loss: 0.3380 - val_accuracy: 0.7757 - val_loss: 0.8718\n",
      "Epoch 19/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9001 - loss: 0.2343 - val_accuracy: 0.6542 - val_loss: 0.9747\n",
      "Epoch 20/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.8473 - loss: 0.3794 - val_accuracy: 0.7944 - val_loss: 0.7947\n",
      "Epoch 21/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.8694 - loss: 0.3456 - val_accuracy: 0.8411 - val_loss: 0.5259\n",
      "Epoch 22/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.9348 - loss: 0.1971 - val_accuracy: 0.8505 - val_loss: 0.4189\n",
      "Epoch 23/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.9619 - loss: 0.1097 - val_accuracy: 0.8411 - val_loss: 0.4513\n",
      "Epoch 24/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step - accuracy: 0.9619 - loss: 0.0978 - val_accuracy: 0.8411 - val_loss: 0.4320\n",
      "Epoch 25/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 253ms/step - accuracy: 0.9651 - loss: 0.0819 - val_accuracy: 0.8411 - val_loss: 0.4295\n",
      "Epoch 26/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 261ms/step - accuracy: 0.9664 - loss: 0.0743 - val_accuracy: 0.8411 - val_loss: 0.3969\n",
      "Epoch 27/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9744 - loss: 0.0692 - val_accuracy: 0.8505 - val_loss: 0.4225\n",
      "Epoch 28/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9705 - loss: 0.0677 - val_accuracy: 0.8505 - val_loss: 0.4198\n",
      "Epoch 29/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.9733 - loss: 0.0642 - val_accuracy: 0.8505 - val_loss: 0.4034\n",
      "Epoch 30/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 268ms/step - accuracy: 0.9801 - loss: 0.0593 - val_accuracy: 0.8598 - val_loss: 0.4082\n",
      "Epoch 31/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9827 - loss: 0.0592 - val_accuracy: 0.8505 - val_loss: 0.4682\n",
      "Epoch 32/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.9732 - loss: 0.0709 - val_accuracy: 0.8598 - val_loss: 0.5559\n",
      "Epoch 33/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 269ms/step - accuracy: 0.9750 - loss: 0.0747 - val_accuracy: 0.8692 - val_loss: 0.4310\n",
      "Epoch 34/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.9655 - loss: 0.0824 - val_accuracy: 0.8785 - val_loss: 0.4073\n",
      "Epoch 35/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 267ms/step - accuracy: 0.9651 - loss: 0.0811 - val_accuracy: 0.8598 - val_loss: 0.3130\n",
      "Epoch 36/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.9650 - loss: 0.0925 - val_accuracy: 0.8785 - val_loss: 0.3234\n",
      "Epoch 37/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 265ms/step - accuracy: 0.9600 - loss: 0.1242 - val_accuracy: 0.8692 - val_loss: 0.4077\n",
      "Epoch 38/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.9712 - loss: 0.0803 - val_accuracy: 0.8598 - val_loss: 0.4696\n",
      "Epoch 39/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.9555 - loss: 0.0986 - val_accuracy: 0.8598 - val_loss: 0.4567\n",
      "Epoch 40/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 262ms/step - accuracy: 0.9613 - loss: 0.1011 - val_accuracy: 0.8037 - val_loss: 1.0442\n",
      "Epoch 41/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 260ms/step - accuracy: 0.9433 - loss: 0.1709 - val_accuracy: 0.8598 - val_loss: 0.4489\n",
      "Epoch 42/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 263ms/step - accuracy: 0.9667 - loss: 0.1022 - val_accuracy: 0.8598 - val_loss: 0.3172\n",
      "Epoch 43/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 264ms/step - accuracy: 0.9594 - loss: 0.0874 - val_accuracy: 0.8505 - val_loss: 0.5842\n",
      "Epoch 44/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 266ms/step - accuracy: 0.9533 - loss: 0.0928 - val_accuracy: 0.8692 - val_loss: 0.3878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22a157fb970>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "K.clear_session(free_memory=True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0eaac-37df-4756-a0de-6c540d33af5f",
   "metadata": {},
   "source": [
    "**Predict and evaluate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecf8ec86-8c22-491d-a402-c751ae3de112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "{0: 128, 1: 239, 2: 58}\n",
      "{0: 40, 1: 75, 2: 19}\n",
      "Accuracy: 0.9328358208955224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fist       0.86      0.95      0.90        40\n",
      "        Palm       0.96      0.97      0.97        75\n",
      "       Thumb       1.00      0.74      0.85        19\n",
      "\n",
      "    accuracy                           0.93       134\n",
      "   macro avg       0.94      0.89      0.91       134\n",
      "weighted avg       0.94      0.93      0.93       134\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fee937",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6c876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# Get the number of layers in the model\n",
    "num_layers = len([layer for layer in model.layers if type(layer) is Dense])\n",
    "\n",
    "# Create the filename\n",
    "filename = f\"only_dense_{num_layers}_layers_no_augmentation_{accuracy:.2f}accuracy.keras\"\n",
    "\n",
    "# Save the model\n",
    "model.save(f\"./saved_models/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8481fc",
   "metadata": {},
   "source": [
    "Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a5a703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DevTools\\Python\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 16 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "filename = \"only_dense_7_layers_0.91_accuracy.keras\"\n",
    "model = tf.keras.models.load_model(f\"./saved_models/{filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7813477",
   "metadata": {},
   "source": [
    "Solution for second pipeline:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc275a95",
   "metadata": {},
   "source": [
    "With same net as in first iteration:\n",
    "\n",
    "One of my first runs had 50% but cant reproduce it\n",
    "Only 3 Minimum Augmentations 256x256 ca. 35,82 Accuracy always pred palm\n",
    "20 Minimum Augmentation 256x256 takes forever to load images, still 35,82\n",
    "\n",
    "With deeper net: \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "20 Minimum Augmentation 256x256, 91% accuracy -> saved this one\n",
    "\n",
    "Try with even deeper net:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(175, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(125, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(75, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "20 Minimum Augmentation 256x256, also 91% accuracy -> saved this one\n",
    "\n",
    "Another try without Augmentation of test data and with dropout: \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "20 Minimum Augmentation 256x256, doesnt get higher than 35% accuracy \n",
    "\n",
    "First net without Test_data augmentation:\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(256, 256, 3)))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(150, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(25, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax')) \n",
    "\n",
    "20 Minimum Augmentation 256x256, 93%\n",
    "\n",
    "Another try without augmenting any data, with \"deeper net\" model:\n",
    "93% -> saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579871fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
